1. NodeJS is event driven, no-blocking (Asynchronous) I/O and cross-platform runtime environment
2.  const express  = require("express");

     const app = express();
	 
	 app.use("/", function(req, res){  // can app.get as well
	        res.send({
			 status: 200,
			 message: "message got successful."
			})
	 
	     });
		 
	app.listen(3000, function(){
	console.log("server has started!!!")
	
	})	 

3. run nodeJS in dev mode install mnodemon 	
4. body-parser lib used to extract body from request parameter 
     const bodyParser = require("body-parser");
     app.use(bodyParser.json())
	 app.use(bodyParser.urlencoded({extened: false}));
	 
5. Streams in nodeJS
Readable, writable, duplex and transform	 

6. Reactor pattern:

A reactor pattern is a concept of non-blocking (I/O) operations. This pattern provide a handler associated with the each I/O operations. as soon as I/O request is generated it is then submitted with the demultiplexer.

7. V8 engine developed by Google in c++. It turns javascript code to machine learning code during execution by utilizing just in time complier. as do many current javascript engines such as spiderMonkey and Rhino ( Mozila).

8. Middleware is a function that takes in a request and response an object.

9. connecting MongoDB client to databse

var MongoClient = require('mongodb').MongoClient;
MongoClient.connect('connectionURL', (err, db)=> {
if(err) throw err;
console.log("Database created!!!");
db.close();

10. for detecting the environment use NODE_ENV

11. global objects are accessabile without requre or import througout the project, like process, console, buffer.

12. A thread pool is a collection of threads that are used to execute tasks in parallel. In Node.js, the thread pool is handled by the libuv library, which is a multi-platform support library that provides asynchronous I/O operations.

13. Worker threads and clusters are two different approaches to leveraging the power of multiple CPUs in Node.js. While clusters create multiple instances of a Node.js process, each running on a separate CPU core, worker threads provide a way to create multiple threads within a single process.
})

14. Tracing is a technique used in Node.js to profile the performance of an application. It involves recording the function calls and events that occur during the execution of the application and analyzing the data to identify performance bottlenecks. 

15. Passport is a popular authentication middleware for Node.js. It provides a simple and modular way to implement authentication in Node.js applications. Passport supports many authentication mechanisms, including username/password, social logins like Facebook and Google, and JSON Web Tokens (JWTs).

16. The express.static() function is a built-in middleware function in Express. It serves static files and is based on serve-static. 
app.use(express.static(path.join(__dirname, 'public')))

17. The primary function of express.json() is to parse requests with a Content-Type header of application/json. Once parsed, the resulting data is stored in the req.body, allowing easy access to the JSON content sent from the client.
app.use(express.json());

18. The urlencoded function is used to parse the incoming requests with URL-encoded payloads. It is a built-in middleware function in Express based on a body parser module.

When there is a HTTP POST request from the client with content type application/x-www-form-urlencoded, this middleware parses the data and populates the req.body object with key-value pairs.

app.use(express.urlencoded({ extended: false }));

19. const EventEmitter = require('events');

class MyEmitter extends EventEmitter {};

const myEmitter = new MyEmitter();
myEmitter.on('event', ()=> { 
      console.log('event emitted!!!');	  
   })
   
myEmitter.emit('event');   

20 Spawn() => used for creating new process with a given command, used for real time streaming, 
  fork() => The fork() method is a specialized version of spawn() that is specifically designed for spawning new Node.js processes. It creates a new instance of the V8 engine to run a separate Node.js script.
  
21. getting current working directory => __dirname, ./, process.cwd()
process.cwd() - Returns the current working directory where the Node.js process was started.
__dirname - Returns the directory name of the current module (file)  

22. npm ci
CI stands for clean install and npm ci is used to install all exact version dependencies or devDependencies from a package-lock.json file. It canâ€™t install additional packages or modify the already installed dependencies.

23. A higher order function (HOF) is a function that takes one or more functions as arguments, or returns a function as its result. 
like map and reduce

24. function composition => chaining of HOF like filter().map()


**************************************************************Database
1. Horizontal / Vertical scalling;:

with SQL only vertical scalling is possible and for NOSql both scalling is possing as there is no scehma to follow.

2. Insert into tab_name (col_name) values (values);

Object Relation mapping library ( Sequelize)

first create models after creating connection

const Products = sequelize.define('products',{
  id: {
  type: Sequelize.STRING,
  autoIncrement: true
  }
})

module.exports = Products;

sequelize.create({}) // for inserting the row
sequelize.findById // .findAll({where: {id: prodId}})
product.save() // for update or create new row
product.destroy() // for deleting the row

*****************************************************************MongoDB
Database => collection => documents

embedded collections/ References

save =d db.collection("products").createOne(object) // .createMany(Array of object)

db.collection("products").find({title: "A book"})


Mongoose => A Object document mapping library

const Schema = mongoose.Schema
const Product = new Schema({
title: {
type: String,
required: true 
},
userId: {   // create association with the different schema
   type: Schema.Types.ObjectId,
   ref: "User",
   required: true
}
})

module.exports = mongoose.model("product", Product)

product.save() // for saving the record
find(), findById() // for get record
findByIdAndRemoved() // for deleting the record


if want to populate whole object instead of just id
product.find().populate("userId").then // will populate whole user object
product.find().select("title name -_id").populate("userId", "name") // give object with title and name and remove _id explicitly 

ObjectId._doc // to fetch whole object for storing 


*****************************************************************
setting cookies

res.setHeader('Set-Cookie', 'loggedIn=true; Max-Age=10; Secure ; HttpOnly')

cookies are stored in client side
session are stored in server side

for session use express-session lib
const session  = require("express-session")
const MongoDBStore = require("connect-mongodb-session")(session);

const store = MongoDBStore({
   path: connectionurl,
   
})

app.use(
   session({
     secret: "abc",
	 resave: false,
	 saveUninitialized: false,
	 store: store
   })
)

// logout using session 

req.session.destroy(() => {
  req.redirect("/");
})


**********jsonwebtoken
jwt.sign(user, secret, callback)
jwt.verify(token, secret, callback)


-------------------------------------
use bcrypt for password storing

bcrypt.encrypt(passwrod, salt value upto 12)

bcrypt.compare(enteredPassword, user.password) => return true or false

if success 
req.session.isLoggedIn = true;
req.session.user = user
req.session.save().than // for storying in mongo db

which can be pass back to client using cookies and can be used for validating request later point of time.


CSRF attack
cross site request forgery  => stealling session and using it
use csrf token embed in form and backend will validate it with every req.body._csrf post request
<input type="hidden" name="_csrf" value="csrfToken" />


set default values in all the requst or rendered views 
app.use((req, res, next) => {
req.locals.isAuthenticated = req.ression.isLoggedIn;
req.locals._csrf = req.csrfToken();
next();
})

password resetting:
used inbuild library crapto library and create has value. and story with the user and expiry time
send reset email to user and validate the has value. and allow to reset value.


password validation => use express-validator/ Validator.js to valildate


***************************************error handling
use try-catch for synchronous error
use than and catch for asynchronous error 

for handling at the middleware level, pass error object to next(err);

and add a middleware at the end with err prop, it will escape all other middleware in between 

app.use((err, req, res, next) => {
req.redirect("/500")
})

Error codes:

2XX (success)  => 200 (operation successed) 201(success, resource created)
3XX (redirect) => 301 (moved permanently )
4XX (client side error) => 400(bad request) 401 (unauthorized) 403(forbidden) 404(not found) 408(request timeout)
5XX (server side error) => 500 (server error) 502 Bad Gateway 504 Gateway Timeout


***********************************Image upload
use multer library for 
set enctype="multipart/form-data"

add middleware aap.use(multer().single('image'))

for downloading file, set response header

res.setHeader("Content-Type", "application/pdf");
res.setHeader("Content-Disposition", "inline; filename: test.pdf");


fs.readFile(invoicePath, (err, data) => {  // will not be good practice as reading big file may be overflow internal memory as it will first copy whole file to memory first
res.setHeader("Content-Type", "application/pdf");
res.setHeader("Content-Disposition", "inline; filename: test.pdf");

res.send(data)})

// should be using streaming for the

const file = fs.createReadStream(invoicePath);
res.setHeader("Content-Type", "application/pdf");
res.setHeader("Content-Disposition", "inline; filename: test.pdf");

file.pipe(res) // stream will forwad data to res or browser with stream 
red


************************************************************Payment
use stripe 3rd party library for Payment 

Process =>

request send to stripe => It will validate the card details => return token => add product/ Payment details => send request back to stripe with token => It will process the request

stripe.checkout.sessions.create({
payment_method_type: ['card'],
line_items: // product details in array
})

stripe.redirectToCheckout({
sessionId: token

})

************************************************************
use app.use(bodyParser.urlencoded())   // if data is send using <form> tag than default format of data is 
                                       // x-www-form-urlencoded 
									   
CORS: Cross origin resource sharing
if server and client are running on different server 


socket.io for server side, socket.io-client for client side

1. intialize the socket.io

import { Server } from 'socket.io';

const app = express();
const server = createServer(app);
const io = new Server(server);

io.on('connection', (socket) => {
console.log("A user is connected!!!");

})

In client side 

 const socket = io();
 
 // emit a event named 'chat message';
 
 const form = document.getElementById('form');
  const input = document.getElementById('input');

  form.addEventListener('submit', (e) => {
    e.preventDefault();
    if (input.value) {
      socket.emit('chat message', input.value);
      input.value = '';
    }
  });
</script>

// capture the event 

io.on('connection', (socket) => {
  socket.on('chat message', (msg) => {
    console.log('message: ' + msg);
  });
});

*************************************secureing request using Helment

const helmet = require('helmet');

app.use(helmet())

Content-Security-Policy: default-src 'self';base-uri 'self';font-src '  // help me xss, script inject, With this policy, your web pages cannot load remote fonts or styles. This is because font-src and style-src are set to self
Referrer-Policy: no-referrer //  no source information, normally source url is there
Strict-Transport-Security: max-age=15552000; includeSubDomains

const compression = require('compression');

app.use(compression());


SSL/TLS ==> 

use ssl certification fron known certificate provider

server send public key to client and client encript the data using public key and send to server
server than decript the data using private key 


EsModule syntex for importing a file

import express from 'express';

for enabling it use type="module" in package.json

and replace moudule.exports to export default 
Node.js >= v13

It's very simple in Node.js 13 and above. You need to either:

Save the file with .mjs extension, or
Add { "type": "module" } in the nearest package.json.
You only need to do one of the above to be able to use ECMAScript modules.


*******************************worker thread vs Child thread
worker thread run on shared environment, same process, only support javascript, 
use case like Image processing, Data processing and transformation, Mathematical computations

const { Worker }  from 'worker_threads';

function calculatePrimes(limit) {
 return new Promise((resolve, reject) => {
 const worker = new Worker('./primeworker.js', {workerData: limit});
 worker.on('message', resolve);
 worker.on('error', reject);
 })
}


Child Process:
fully isolated, system level task or external code, communicate using Inter-process communication, understand any scripting language

const { fork } = require('child_process');

const child = fork('./childService.js');

child.on('message', (message) => {
  console.log('Message from child:', message);
});

// Send a task to the child process
child.send({ task: 'processData', payload: [1, 2, 3] });



Exec is typically used for short-lived processes, while fork and spawn are typically used for long-lived processes.
Exec allows for capturing the child processâ€™s output and error streams, while fork and spawn stream the output and error streams back to the parent process.
Fork allows for IPC between the parent and child processes, while exec and spawn do not.

The fork method will open an IPC channel allowing message passing between Node processes:

On the child process, process.on(â€˜messageâ€™) and process.send(â€˜message to parentâ€™) can be used to receive and send data
On the parent process, child.on(â€˜messageâ€™) and child.send(â€˜message to childâ€™) are used

Spawn create fresh new node process, while fork, fork the parent process and create new process.


CI/CD pipeline

1. Build
2. Test
3. Deploy 

Inside Build proces:

aure_pipeline.yaml

name: wired Brain

trigger: 
  -main
  
stages:
  
   -stage: BuildAndTest
    jobs:
    - job: Build
      pool: 
        vmImage: 'ubunto-latest'
      steps:
      - task: UseDorNet	  
  
  
Microservice: 

Microservices are small, autonomous service that work together.

key characteristics 
small, bounded context, loosely coupled, Autonomous
each service should have sperate database
communication through api only 

drawbacks of monolithic application:

1. Lack of partial scalability
2. Lack of language flexiablity 
3. Long development cycles 
4. Lack of fault isolation

bounded context: define the boundaries of each microservice and aling them with specific business requirement.
scalability


for communication use message broker and queues 
RabbitMQ and kafka 


RabbitMQ is one the most popular message brokers that runs on top of Advanced Message Queuing Protocol (AMQP).
main components forming AMQP protocol: Publisher, Exchange, Queue, Consumer.
Use cases for RabbitMQ encompass areas like order processing in eCommerce, real-time notifications, and multiplayer gaming, showcasing its adaptability to different operational needs.


https://dev.to/pharzad/introduction-to-rabbitmq-for-node-js-developers-1clm   // just go through this link for RabbitMQ

running nodejs application in multi-threaded mode

Child processes launch another application (not necessarily a JavaScript one), pass data, and receive a result typically via a callback. They operate in a similar way to workers, but theyâ€™re generally less efficient and more process-intensive, because theyâ€™re dependent on processes outside Node.js. There may also be OS differences and incompatibilities. Node.js has three general child process types with synchronous and asynchronous variations:
spawn: spawns a new process
exec: spawns a shell and runs a command within it
fork: spawns a new Node.js process

JavaScript runtimes use a single processing thread, which can cause bottlenecks in Node.js apps handling multiple user requests. Multithreading can help prevent these bottlenecks.
Node.js worker threads allow for asynchronous processing on a separate thread, improving performance. However, they canâ€™t handle complex objects like database connections, and data must be serialized when passed to and from a worker.
Node.js child processes can launch another application, pass data, and receive a result. They are less efficient than workers and more process-intensive, but can be used when dependent on processes outside Node.js.
Node.js clusters allow forking of identical processes to handle loads more efficiently. They can also handle restarts when an instance fails and broker communication between forked processes, but code can become increasingly complex.
Process managers and container orchestration can run multiple instances of a Node.js application without having to write cluster code, making them ideal for live servers. Containers emulate an operating system, allowing an application to run on a single device or across thousands of machines.



NodeMailer is the most popular npm module for sending emails from Node.js applications, with over three million downloads a week. It requires an SMTP server to send emails.

const transporter = nodemailer.createTransport({
  host: 'smtp.freesmtpservers.com',
  port: 25
});

try {

  const send = await transporter.sendMail({
    from: '"Test Email" <test@email.com>',  // sender address
    to: 'someone@example.com',              // list of receivers
    subject: 'Hello!',                      // subject line
    text: 'Hello world!',                   // plain text body
    html: '<p>Hello world!</p>',            // HTML body
  });
  
  https://www.sitepoint.com/sending-email-using-node-js/
  
  __________________________________________________________________________________________
  
  Redis, short for Remote Dictionary Server, is an open-source, in-memory data store.
  
  Redis is renowned for its exceptional speed, making it an ideal choice for caching and real-time applications.
  
  / Node.js code for caching with Redis
const redis = require('redis');
const client = redis.createClient();

// Middleware to check the cache before fetching data
function checkCache(req, res, next) {
    const key = req.path;
    // Check if data is in cache
    client.get(key, (err, data) => {
        if (err) throw err;
        if (data) {
            // Data found in cache, use it
            res.json(JSON.parse(data));
        } else {
            // Data not in cache, fetch from an API (placeholder URL)
            fetch('https://api.example.com' + req.path)
                .then((response) => response.json())
                .then((data) => {
                    // Store data in cache for future use (with an expiration time of 1 hour)
                    client.setex(key, 3600, JSON.stringify(data));
                    res.json(data);
                })
                .catch((error) => {
                    res.status(500).json({ error: 'An error occurred while fetching data.' });
                });
        }
    });
}
// Endpoint for fetching data with caching
app.get('/api/data', checkCache, (req, res) => {
    // This code will only execute if the data is not in the cache
    console.log('Fetching data from the API...');
});

Session Management
Redis is also adept at handling session management in web applications. Storing session data in Redis ensures scalability and session persistence.

// Node.js code for session management with Redis
const redis = require('redis');
const session = require('express-session');
const RedisStore = require('connect-redis')(session);

// Create a Redis session store
const client = redis.createClient();
const sessionStore = new RedisStore({ client });
// Use it with Express.js
app.use(session({
    store: sessionStore,
    secret: 'your-secret-key',
    resave: false,
    saveUninitialized: true,
    cookie: { secure: false },
}));


Real-time Analytics
Redisâ€™s speed and support for data structures make it an excellent choice for real-time analytics.

You can use Redis to store counters, collect metrics, and generate real-time reports, as demonstrated below:
// Node.js code for real-time analytics with Redis
const redis = require('redis');
const client = redis.createClient();

// Increment a counter
client.incr('pageViews', (err, count) => {
    if (err) throw err;
    // Use the updated count for real-time reporting
    console.log(`Total Page Views: ${count}`);
});
  
